{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ca6d634b42b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "conn = sqlite3.connect(\"db.sqlite3\")\n",
    "df = pd.read_sql_query(\"select * from submissions limit 5000;\", conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_subs</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>26256285</td>\n",
       "      <td>People who haven't pooped in 2019 yet, why are...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>26256285</td>\n",
       "      <td>Stan Lee has passed away at 95 years old</td>\n",
       "      <td>As many of you know today is day that many of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Home</td>\n",
       "      <td>10068</td>\n",
       "      <td>Beautiful Home :)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Home</td>\n",
       "      <td>10068</td>\n",
       "      <td>This was finished yesterday..</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>videos</td>\n",
       "      <td>22083867</td>\n",
       "      <td>This is what happens when one company owns doz...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>videos</td>\n",
       "      <td>22083867</td>\n",
       "      <td>Youtube is Facilitating the Sexual Exploitatio...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>news</td>\n",
       "      <td>19783893</td>\n",
       "      <td>Blizzard Employees Staged a Walkout After the ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>news</td>\n",
       "      <td>19783893</td>\n",
       "      <td>Kobe Bryant killed in helicopter crash in Cali...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>23061646</td>\n",
       "      <td>Trump Impeached for Abuse of Power</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>23061646</td>\n",
       "      <td>Two weeks before his inauguration, Donald J. T...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit  subreddit_subs  \\\n",
       "0  AskReddit        26256285   \n",
       "1  AskReddit        26256285   \n",
       "2       Home           10068   \n",
       "3       Home           10068   \n",
       "4     videos        22083867   \n",
       "5     videos        22083867   \n",
       "6       news        19783893   \n",
       "7       news        19783893   \n",
       "8  worldnews        23061646   \n",
       "9  worldnews        23061646   \n",
       "\n",
       "                                               title  \\\n",
       "0  People who haven't pooped in 2019 yet, why are...   \n",
       "1           Stan Lee has passed away at 95 years old   \n",
       "2                                  Beautiful Home :)   \n",
       "3                      This was finished yesterday..   \n",
       "4  This is what happens when one company owns doz...   \n",
       "5  Youtube is Facilitating the Sexual Exploitatio...   \n",
       "6  Blizzard Employees Staged a Walkout After the ...   \n",
       "7  Kobe Bryant killed in helicopter crash in Cali...   \n",
       "8                 Trump Impeached for Abuse of Power   \n",
       "9  Two weeks before his inauguration, Donald J. T...   \n",
       "\n",
       "                                                text  \n",
       "0                                                     \n",
       "1  As many of you know today is day that many of ...  \n",
       "2                                                     \n",
       "3                                                     \n",
       "4                                                     \n",
       "5                                                     \n",
       "6                                                     \n",
       "7                                                     \n",
       "8                                                     \n",
       "9                                                     "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                     \n",
       "1    As many of you know today is day that many of ...\n",
       "2                                                     \n",
       "3                                                     \n",
       "4                                                     \n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['text'].str.replace('[^\\w\\s]',' ')\n",
    "df['clean_title'] = df['title'].str.replace('[^\\w\\s]',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_subs</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>26256285</td>\n",
       "      <td>People who haven't pooped in 2019 yet, why are...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>People who haven t pooped in 2019 yet  why are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>26256285</td>\n",
       "      <td>Stan Lee has passed away at 95 years old</td>\n",
       "      <td>As many of you know today is day that many of ...</td>\n",
       "      <td>As many of you know today is day that many of ...</td>\n",
       "      <td>Stan Lee has passed away at 95 years old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Home</td>\n",
       "      <td>10068</td>\n",
       "      <td>Beautiful Home :)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Beautiful Home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Home</td>\n",
       "      <td>10068</td>\n",
       "      <td>This was finished yesterday..</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>This was finished yesterday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>videos</td>\n",
       "      <td>22083867</td>\n",
       "      <td>This is what happens when one company owns doz...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>This is what happens when one company owns doz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>videos</td>\n",
       "      <td>22083867</td>\n",
       "      <td>Youtube is Facilitating the Sexual Exploitatio...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Youtube is Facilitating the Sexual Exploitatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>news</td>\n",
       "      <td>19783893</td>\n",
       "      <td>Blizzard Employees Staged a Walkout After the ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Blizzard Employees Staged a Walkout After the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>news</td>\n",
       "      <td>19783893</td>\n",
       "      <td>Kobe Bryant killed in helicopter crash in Cali...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Kobe Bryant killed in helicopter crash in Cali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>23061646</td>\n",
       "      <td>Trump Impeached for Abuse of Power</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Trump Impeached for Abuse of Power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>23061646</td>\n",
       "      <td>Two weeks before his inauguration, Donald J. T...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Two weeks before his inauguration  Donald J  T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit  subreddit_subs  \\\n",
       "0  AskReddit        26256285   \n",
       "1  AskReddit        26256285   \n",
       "2       Home           10068   \n",
       "3       Home           10068   \n",
       "4     videos        22083867   \n",
       "5     videos        22083867   \n",
       "6       news        19783893   \n",
       "7       news        19783893   \n",
       "8  worldnews        23061646   \n",
       "9  worldnews        23061646   \n",
       "\n",
       "                                               title  \\\n",
       "0  People who haven't pooped in 2019 yet, why are...   \n",
       "1           Stan Lee has passed away at 95 years old   \n",
       "2                                  Beautiful Home :)   \n",
       "3                      This was finished yesterday..   \n",
       "4  This is what happens when one company owns doz...   \n",
       "5  Youtube is Facilitating the Sexual Exploitatio...   \n",
       "6  Blizzard Employees Staged a Walkout After the ...   \n",
       "7  Kobe Bryant killed in helicopter crash in Cali...   \n",
       "8                 Trump Impeached for Abuse of Power   \n",
       "9  Two weeks before his inauguration, Donald J. T...   \n",
       "\n",
       "                                                text  \\\n",
       "0                                                      \n",
       "1  As many of you know today is day that many of ...   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4                                                      \n",
       "5                                                      \n",
       "6                                                      \n",
       "7                                                      \n",
       "8                                                      \n",
       "9                                                      \n",
       "\n",
       "                                          clean_text  \\\n",
       "0                                                      \n",
       "1  As many of you know today is day that many of ...   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4                                                      \n",
       "5                                                      \n",
       "6                                                      \n",
       "7                                                      \n",
       "8                                                      \n",
       "9                                                      \n",
       "\n",
       "                                         clean_title  \n",
       "0  People who haven t pooped in 2019 yet  why are...  \n",
       "1           Stan Lee has passed away at 95 years old  \n",
       "2                                  Beautiful Home     \n",
       "3                      This was finished yesterday    \n",
       "4  This is what happens when one company owns doz...  \n",
       "5  Youtube is Facilitating the Sexual Exploitatio...  \n",
       "6  Blizzard Employees Staged a Walkout After the ...  \n",
       "7  Kobe Bryant killed in helicopter crash in Cali...  \n",
       "8                 Trump Impeached for Abuse of Power  \n",
       "9  Two weeks before his inauguration  Donald J  T...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set our features as description, and target as subreddit.  \n",
    "# Create a mass text.\n",
    "\n",
    "features = ['clean_text', 'clean_title', 'subreddit_subs'] \n",
    "target = 'subreddit'\n",
    "\n",
    "X = df[features]\n",
    "y = df[[target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spacy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-7a10ab5a1241>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Create the nlp object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"en_core_web_md\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# create tokenizer object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spacy' is not defined"
     ]
    }
   ],
   "source": [
    "#Create the nlp object\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# create tokenizer object\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "        \"\"\"Return the tokens\"\"\"\n",
    "        return [token.text for token in tokenizer(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemmas(text):\n",
    "        \"\"\"Return the Lemmas\"\"\"\n",
    "        lemmas = []\n",
    "        doc = nlp(text)\n",
    "    \n",
    "        for token in doc: \n",
    "            if ((token.is_stop == False) and (token.is_punct == False)) and (token.pos_ != 'PRON'):\n",
    "                lemmas.append(token.lemma_)\n",
    "    \n",
    "        return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df[\"clean_text\"]\n",
    "\n",
    "# Instantiate vectorizer object\n",
    "#tfidf = TfidfVectorizer(tokenizer=get_lemmas, min_df=0.025, max_df=.98, ngram_range=(1,2))\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\")\n",
    "# Create a vocabulary and get word counts per document\n",
    "dtm = tfidf.fit_transform(text) # Similiar to fit_predict\n",
    "\n",
    "# Get feature names to use as dataframe column headers\n",
    "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=None, n_neighbors=5, p=2, radius=1.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on TF-IDF Vectors\n",
    "size = 5\n",
    "nn  = NearestNeighbors(n_neighbors=size, algorithm='ball_tree')\n",
    "nn.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = [\"\"\"Capes are not a great idea of you are a super hero trying to save the world.\"\"\"]\n",
    "\n",
    "vec_user_input = tfidf.transform(user_input)\n",
    "dist, subreddit_index = nn.kneighbors(vec_user_input.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[          subreddit                                              title text  \\\n",
      "871         Gunners  Invincibles. If you upvote this, it literally ...        \n",
      "878  netflixwitcher                                  To all the Morons        \n",
      "873      IncelTears  The final boss all Incels must face after all ...        \n",
      "872      IncelTears                                    Just a reminder        \n",
      "877   tipofmytongue  [TOMT] What is the name of ankles, but above y...        \n",
      "\n",
      "     subscribers  \n",
      "871       148652  \n",
      "878        73465  \n",
      "873       338967  \n",
      "872       338967  \n",
      "877      1045371  ]\n"
     ]
    }
   ],
   "source": [
    "recommended_reddits = [df[['subreddit','title','text','subscribers']].iloc[n] for n in subreddit_index]\n",
    "\n",
    "print(recommended_reddits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do pickling here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
