{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "conn = sqlite3.connect(\"db.sqlite3\")\n",
    "df = pd.read_sql_query(\"select * from submissions limit 5000;\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "import itertools, string, operator, re, unicodedata, nltk\n",
    "import nltk\n",
    "from operator import itemgetter\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer, RegexpTokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from gensim.models import Phrases\n",
    "from collections import Counter\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "'''Features'''\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "'''Classifiers'''\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "'''Metrics/Evaluation'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "\n",
    "'''Plotting'''\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>26241971</td>\n",
       "      <td>People who haven't pooped in 2019 yet, why are...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>26241971</td>\n",
       "      <td>Stan Lee has passed away at 95 years old</td>\n",
       "      <td>As many of you know today is day that many of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home</td>\n",
       "      <td>10022</td>\n",
       "      <td>Beautiful Home :)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home</td>\n",
       "      <td>10022</td>\n",
       "      <td>My roommate is kicking me out because having a...</td>\n",
       "      <td>So, I am not asking for advice, really...mores...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>videos</td>\n",
       "      <td>22077202</td>\n",
       "      <td>This is what happens when one company owns doz...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>videos</td>\n",
       "      <td>22077202</td>\n",
       "      <td>Youtube is Facilitating the Sexual Exploitatio...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>news</td>\n",
       "      <td>19777808</td>\n",
       "      <td>Blizzard Employees Staged a Walkout After the ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>news</td>\n",
       "      <td>19777808</td>\n",
       "      <td>Kobe Bryant killed in helicopter crash in Cali...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>23055673</td>\n",
       "      <td>Trump Impeached for Abuse of Power</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>23055673</td>\n",
       "      <td>Two weeks before his inauguration, Donald J. T...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit  subscribers                                              title  \\\n",
       "0  AskReddit     26241971  People who haven't pooped in 2019 yet, why are...   \n",
       "1  AskReddit     26241971           Stan Lee has passed away at 95 years old   \n",
       "2       Home        10022                                  Beautiful Home :)   \n",
       "3       Home        10022  My roommate is kicking me out because having a...   \n",
       "4     videos     22077202  This is what happens when one company owns doz...   \n",
       "5     videos     22077202  Youtube is Facilitating the Sexual Exploitatio...   \n",
       "6       news     19777808  Blizzard Employees Staged a Walkout After the ...   \n",
       "7       news     19777808  Kobe Bryant killed in helicopter crash in Cali...   \n",
       "8  worldnews     23055673                 Trump Impeached for Abuse of Power   \n",
       "9  worldnews     23055673  Two weeks before his inauguration, Donald J. T...   \n",
       "\n",
       "                                                text  \n",
       "0                                                     \n",
       "1  As many of you know today is day that many of ...  \n",
       "2                                                     \n",
       "3  So, I am not asking for advice, really...mores...  \n",
       "4                                                     \n",
       "5                                                     \n",
       "6                                                     \n",
       "7                                                     \n",
       "8                                                     \n",
       "9                                                     "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['text'].str.replace('[^\\w\\s]',' ')\n",
    "df['clean_title'] = df['title'].str.replace('[^\\w\\s]',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['clean_text'] + df['clean_title']\n",
    "df['text'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "tokens = []\n",
    "\n",
    "\"\"\" Make them tokens \"\"\"\n",
    "\n",
    "#stop words\n",
    "STOP_WORDS = nlp.Defaults.stop_words.union(['', ' ', '-', 'reddit', 'post'])\n",
    "    \n",
    "tokens = []\n",
    "\n",
    "for doc in tokenizer.pipe(df['text'], batch_size=500):\n",
    "    \n",
    "    doc_tokens = []\n",
    "    \n",
    "    for token in doc: \n",
    "        if token.text.lower() not in STOP_WORDS:\n",
    "            doc_tokens.append(token.text.lower())\n",
    "   \n",
    "    tokens.append(doc_tokens)\n",
    "    \n",
    "df['tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemmas(text):\n",
    "        \"\"\"Return the Lemmas\"\"\"\n",
    "        lemmas = []\n",
    "        doc = nlp(text)\n",
    "    \n",
    "        for token in doc: \n",
    "            if ((token.is_stop == False) and (token.is_punct == False)) and (token.pos_ != 'PRON'):\n",
    "                lemmas.append(token.lemma_)\n",
    "    \n",
    "        return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=get_lemmas, min_df=0.025, max_df=.98, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 209)\t0.6323333777801103\n",
      "  (0, 257)\t0.457409810351627\n",
      "  (0, 5)\t0.2226138083134785\n",
      "  (0, 221)\t0.3713266142454971\n",
      "  (0, 177)\t0.4510991051204054\n",
      "  (1, 131)\t0.12950290676325846\n",
      "  (1, 22)\t0.14038666849782563\n",
      "  (1, 147)\t0.1695834056692183\n",
      "  (1, 37)\t0.15215144985933243\n",
      "  (1, 172)\t0.14872061636910663\n",
      "  (1, 2)\t0.15689893562254523\n",
      "  (1, 6)\t0.1246666611279185\n",
      "  (1, 162)\t0.1546311721018806\n",
      "  (1, 95)\t0.17127526686218691\n",
      "  (1, 211)\t0.16744262294017062\n",
      "  (1, 74)\t0.12895313918848877\n",
      "  (1, 130)\t0.12941070423807302\n",
      "  (1, 8)\t0.2644404719205803\n",
      "  (1, 251)\t0.12941070423807302\n",
      "  (1, 237)\t0.14572707696501988\n",
      "  (1, 161)\t0.15593692542143042\n",
      "  (1, 197)\t0.17041957466149782\n",
      "  (1, 241)\t0.12171439122127248\n",
      "  (1, 146)\t0.2835588557760236\n",
      "  (1, 200)\t0.09509881808828502\n",
      "  :\t:\n",
      "  (4997, 26)\t0.750564444452597\n",
      "  (4997, 155)\t0.5996310305927084\n",
      "  (4997, 5)\t0.27766101972349483\n",
      "  (4998, 47)\t0.17100308555262075\n",
      "  (4998, 180)\t0.1519913552779669\n",
      "  (4998, 141)\t0.16406304158526636\n",
      "  (4998, 49)\t0.14187843476421208\n",
      "  (4998, 220)\t0.14815037455769828\n",
      "  (4998, 72)\t0.3043208810317139\n",
      "  (4998, 102)\t0.33603188169747494\n",
      "  (4998, 126)\t0.15233030675068812\n",
      "  (4998, 175)\t0.17157326712065002\n",
      "  (4998, 99)\t0.16907431531393996\n",
      "  (4998, 69)\t0.16070728277419338\n",
      "  (4998, 205)\t0.14200679780712294\n",
      "  (4998, 153)\t0.1531916101567502\n",
      "  (4998, 43)\t0.25716481454002754\n",
      "  (4998, 147)\t0.17016405354583847\n",
      "  (4998, 146)\t0.14226487587997022\n",
      "  (4998, 140)\t0.11863282219974071\n",
      "  (4998, 257)\t0.12452957940333578\n",
      "  (4998, 5)\t0.60606491796364\n",
      "  (4998, 221)\t0.1010934747064329\n",
      "  (4999, 246)\t0.9290182163565368\n",
      "  (4999, 5)\t0.3700339898951433\n",
      "(5000, 259)\n"
     ]
    }
   ],
   "source": [
    "#Creating the features (tf-idf weights) for the processed text\n",
    "\n",
    "\n",
    "#texts = df['text'].astype('str')\n",
    "\n",
    "\n",
    "#tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 3), \n",
    "                                 #  min_df = 1, \n",
    "                                  # max_df = .95)\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(df.text) #features\n",
    "y = df['subreddit'].values #target\n",
    "\n",
    "print(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 258)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "#dimensionality reduction\n",
    "lsa = TruncatedSVD(n_components=258, \n",
    "                   n_iter=10, \n",
    "                   random_state=3)\n",
    "\n",
    "X_text = lsa.fit_transform(X)\n",
    "print(X_text.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-40601c5cb20f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m                                                     \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                                                     \u001b[0mstratify\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                                                     random_state = 3)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#Function to get the scores for each model in a df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2207\u001b[0m                      random_state=random_state)\n\u001b[1;32m   2208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2209\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m     return list(chain.from_iterable((safe_indexing(a, train),\n",
      "\u001b[0;32m~/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \"\"\"\n\u001b[1;32m   1314\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1316\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mclass_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m             raise ValueError(\"The least populated class in y has only 1\"\n\u001b[0m\u001b[1;32m   1696\u001b[0m                              \u001b[0;34m\" member, which is too few. The minimum\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m                              \u001b[0;34m\" number of groups for any class cannot\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "#Preliminary model evaluation using default parameters\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "\n",
    "#Creating a dict of the models\n",
    "model_dict = {'Dummy' : DummyClassifier(random_state=3),\n",
    "              'Stochastic Gradient Descent' : SGDClassifier(random_state=3, loss='log'),\n",
    "              'Random Forest': RandomForestClassifier(random_state=3),\n",
    "              'AdaBoost': AdaBoostClassifier(random_state=3),\n",
    "              'Gaussian Naive Bayes': GaussianNB(),\n",
    "              'K Nearest Neighbor': KNeighborsClassifier()}\n",
    "\n",
    "#Train test split with stratified sampling for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_text, \n",
    "                                                    y, \n",
    "                                                    test_size = .5, \n",
    "                                                    shuffle = True, \n",
    "                                                    stratify = y, \n",
    "                                                    random_state = 3)\n",
    "\n",
    "#Function to get the scores for each model in a df\n",
    "def model_score_df(model_dict):   \n",
    "    model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "    for k,v in model_dict.items():   \n",
    "        model_name.append(k)\n",
    "        v.fit(X_train, y_train)\n",
    "        y_pred = v.predict(X_test)\n",
    "        ac_score_list.append(accuracy_score(y_test, y_pred))\n",
    "        p_score_list.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        r_score_list.append(recall_score(y_test, y_pred, average='macro'))\n",
    "        f1_score_list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "        model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "        model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "    return model_comparison_df\n",
    "\n",
    "model_score_df(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP (numpy updates)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
